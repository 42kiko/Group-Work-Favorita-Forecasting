from __future__ import annotations

import pandas as pd
import streamlit as st

from Favorita_TSA.preprocess_eda import load_table
from Favorita_TSA.utils.dataset import PreDataset

# If your app.py already sets the Plotly theme globally, nothing needed here.

st.set_page_config(page_title="Forecast Candidates", layout="wide")
st.title("ðŸ”Ž Forecast Candidates (Store-Item) â€” Table View")


# -----------------------------
# Cached data loading
# -----------------------------
@st.cache_data(show_spinner=True)
def load_store_item_daily() -> pd.DataFrame:
    df = load_table(PreDataset.STORE_ITEM_DAILY).copy()

    # Ensure types
    df["date"] = pd.to_datetime(df["date"])
    # Guard against missing columns
    required = {"store_nbr", "item_nbr", "date", "unit_sales_sum"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"Missing columns in STORE_ITEM_DAILY: {sorted(missing)}")

    return df


@st.cache_data(show_spinner=True)
def build_store_item_summary(df: pd.DataFrame) -> pd.DataFrame:
    # Global date range (for coverage)
    global_start = df["date"].min()
    global_end = df["date"].max()
    global_days = (global_end - global_start).days + 1

    g = df.groupby(["store_nbr", "item_nbr"], as_index=False)

    summary = g.agg(
        first_date=("date", "min"),
        last_date=("date", "max"),
        n_rows=(
            "date",
            "size",
        ),  # number of daily records for this pair (should be ~days active)
        n_days_observed=("date", "nunique"),  # unique days present in this aggregate
        total_units=("unit_sales_sum", "sum"),
        mean_units=("unit_sales_sum", "mean"),
        std_units=("unit_sales_sum", "std"),
        max_units=("unit_sales_sum", "max"),
        n_days_sold=("unit_sales_sum", lambda s: (s > 0).sum()),
        n_days_zero=("unit_sales_sum", lambda s: (s <= 0).sum()),
    )

    # Derived metrics
    summary["active_span_days"] = (
        summary["last_date"] - summary["first_date"]
    ).dt.days + 1
    summary["coverage_global"] = summary["n_days_observed"] / float(global_days)
    summary["sell_through"] = summary["n_days_sold"] / summary["n_days_observed"].clip(
        lower=1
    )
    summary["zero_share"] = summary["n_days_zero"] / summary["n_days_observed"].clip(
        lower=1
    )

    # Stability proxy (lower is better): Coefficient of Variation (CV)
    # Avoid div by 0
    summary["cv"] = summary["std_units"] / summary["mean_units"].replace(0, pd.NA)

    # Clean up NaNs
    summary["std_units"] = summary["std_units"].fillna(0.0)
    summary["cv"] = summary["cv"].fillna(pd.NA)

    # Helpful ordering
    summary = summary.sort_values(["total_units"], ascending=False).reset_index(
        drop=True
    )

    # Format-friendly columns
    summary["first_date"] = summary["first_date"].dt.date
    summary["last_date"] = summary["last_date"].dt.date

    return summary


df = load_store_item_daily()
summary = build_store_item_summary(df)

# -----------------------------
# Sidebar filters
# -----------------------------
with st.sidebar:
    st.header("Filters")

    # Fast coarse filters
    min_total_units = st.number_input(
        "Min total units", min_value=0.0, value=0.0, step=100.0
    )
    min_days_sold = st.number_input("Min days sold", min_value=0, value=0, step=10)
    min_coverage = st.slider("Min global coverage", 0.0, 1.0, 0.0, 0.01)
    max_zero_share = st.slider("Max zero share", 0.0, 1.0, 1.0, 0.01)

    # Optional focus filters
    store_pick = st.selectbox(
        "Store (optional)",
        options=[None, *sorted(summary["store_nbr"].unique())],
        index=0,
        key="fc_store_pick",
    )
    item_pick = st.selectbox(
        "Item (optional)",
        options=[None, *sorted(summary["item_nbr"].unique())],
        index=0,
        key="fc_item_pick",
    )

    # Display controls
    top_n = st.slider("Rows to show", 100, 5000, 500, 100)
    sort_by = st.selectbox(
        "Sort by",
        options=[
            "total_units",
            "n_days_sold",
            "sell_through",
            "coverage_global",
            "zero_share",
            "cv",
            "max_units",
        ],
        index=0,
        key="fc_sort_by",
    )
    sort_asc = st.checkbox("Sort ascending", value=False)

# -----------------------------
# Apply filters
# -----------------------------
f = summary.copy()

f = f.loc[f["total_units"] >= float(min_total_units)]
f = f.loc[f["n_days_sold"] >= int(min_days_sold)]
f = f.loc[f["coverage_global"] >= float(min_coverage)]
f = f.loc[f["zero_share"] <= float(max_zero_share)]

if store_pick is not None:
    f = f.loc[f["store_nbr"] == store_pick]

if item_pick is not None:
    f = f.loc[f["item_nbr"] == item_pick]

# Sort + limit
f = f.sort_values(sort_by, ascending=sort_asc).head(int(top_n)).reset_index(drop=True)

# -----------------------------
# Headline metrics
# -----------------------------
c1, c2, c3, c4 = st.columns(4)
c1.metric("Total pairs (all)", f"{len(summary):,}")
c2.metric("After filters", f"{len(f):,}")
c3.metric("Unique stores", f"{f['store_nbr'].nunique():,}")
c4.metric("Unique items", f"{f['item_nbr'].nunique():,}")

st.divider()

# -----------------------------
# Table
# -----------------------------
st.subheader("ðŸ“‹ Store-Item Summary Table")

# Choose columns for display (keep it readable)
display_cols = [
    "store_nbr",
    "item_nbr",
    "first_date",
    "last_date",
    "active_span_days",
    "n_days_observed",
    "n_days_sold",
    "sell_through",
    "zero_share",
    "coverage_global",
    "total_units",
    "mean_units",
    "std_units",
    "cv",
    "max_units",
]

st.dataframe(
    f[display_cols],
    use_container_width=True,
    hide_index=True,
)

st.caption(
    "Tip: use filters to find candidates that have (1) enough sold days, "
    "(2) low zero_share, and (3) reasonable coverage. Those are usually forecastable."
)
